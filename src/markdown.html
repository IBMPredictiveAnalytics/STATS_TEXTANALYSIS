<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>STATS TEXTANALYSIS</title>

<link rel="stylesheet" type="text/css" href="extsyntax.css" />

</head>

<body>
<h1>STATS TEXTANALYSIS</h1>

<p>Tools for analysis of text</p>
<div class="syntax">
<p>STATS TEXTANALYSIS
VARIABLES variable list<br/>
OVERWRITE = NO<sup>&#42;&#42;</sup> or Yes</p>
STOPWORDSLANG = ENGLISH<sup>&#42;&#42;</sup> OR ARABIC OR AZERBAIJANI OR DANISH OR DUTCH OR FINNISH OR FRENCH OR 
GERMAN OR GREEK OR HUNGARIAN OR INDONESIAN OR ITALIAN OR KAZAKH OR NEPALI OR 
NONE OR NORWEGIAN OR PORTUGUESE OR ROMANIAN OR RUSSIAN OR SLOVENE OR 
SPANISH OR SWEDISH OR TAJIK OR TURKISH<br/>
STEMMERLANG = ENGLISH<sup>&#42;&#42;</sup> OR ARABIC OR DANISH OR DUTCH OR FINNISH OR FRENCH OR GERMAN 
OR HUNGARIAN OR ITALIAN OR NORWEGIAN OR PORTER OR PORTUGUESE OR 
ROMANIAN OR RUSSIAN OR SPANISH OR SWEDISH</p>

<p>/SPELLING 
DOSPELLING = NO<sup>&#42;&#42;</sup> or YES<br/>
EXCLUDENAMES = NO<sup>&#42;&#42;</sup> or YES<br/>
EXTRADICT = "file specification" <br/>
SUFFIX = name suffix<br/>
LANGUAGE = ENGLISH<sup>&#42;&#42;</sup> OR SPANISH OR GERMAN OR FRENCH OR PORTGUESE</p>

<p>/FREQUENCIES
DOFREQ = NO<sup>&#42;&#42;</sup>or YES<br/>
STEM = NO<sup>&#42;&#42;</sup> or YES<br/>
COUNT = number</p>

<p>/SENTIMENT<br/>
DOSENT = NO<sup>&#42;&#42;</sup> or YES<br/>
TYPES = NEG NEU POS COMP<br/>
SUFFIXES = suffix for each selected type</p>

<p>/SEARCH
DOSEARCH = NO<sup>&#42;&#42;</sup> or YES<br/>
WORDS = list of words<br/>
MODE = ANYWORDS<sup>&#42;&#42;</sup> or ALLWORDS or PATTERN<br/>
POSP = part-of-speech terms<br/>
LANG = eng<sup>&#42;&#42;</sup> see list below<br/>
SUFFIX = name suffix<br/>
STEM = NO<sup>&#42;&#42;</sup> or YES<br/>
DISPLAYSYN= NO<sup>&#42;&#42;</sup> or YES<br/>
Alternate WORD and POSP syntax:<br/>
WORDS = term(poslist) term(poslist) ...</p>

<p>/ENTITYSEARCH<br/>
DOESEARCH = NO<sup>&#42;&#42;</sup> or YES<br/>
ETYPE = ALLTYPES or ORG or PER or LOC or FAC or GPE<br/>
SUFFIX = suffix for new variables<br/>
OUTSIZE = integer</p>


<p>/LEXICON
DOLEXICON NO<sup>&#42;&#42;</sup> or YES<br/>
DSNAME = dataset name</p>

<p>/WORDSCORES
DOSCORES = NO<sup>&#42;&#42;</sup> or YES<br/>
FILE = "file specification"</p>

<p>/SPECIALTERMS DOTERMS = NO<sup>&#42;&#42;</sup>or YES<br/>
NEGATIONDSNAME = new dataset name<br/>
EMPHASISDSNAME = new dataset name<br/>
NEGATIONFILE = file specification<br/>
EMPHASISFILE = file specification</p>

<p>/STEMS
DOSTEMS = NO<sup>&#42;&#42;</sup> or YES<br/>
SUFFIX = name suffix</p>

<p>/HELP</p>

<p><sup>&#42;</sup> Required<br/>
<sup>&#42;&#42;</sup> Default</p>
</div>
<p>STATS TEXTANALYSIS/HELP displays this help and does nothing else.</p>


<pre class="example"><code>
STATS TEXTANALYSIS VARIABLES = qjob
/FREQUENCIES DOFREQ = YES STEM = YES COUNT = 20.
</code></pre>
<pre class="example"><code>
STATS TEXTANALYSIS VARIABLES = qsatisfaction
/SENTIMENT DOSENT = YES TYPES=COMP SUFFIXES = compound.
</code></pre>

  <p>This procedure
 provides tools for working with text data.  It is meant
 for short text strings such as might occur in a survey question with an "Other" category
 or open-ended questions such as opinions.  There is a document entitled <i>Analyzing Survey Text</i> on using
 this tool to work with text that is installed in the STATS_TEXTANALYSIS
 directory under the location where the command is installed.</p>
 
 <p>The tool supports case weights, but weights are rounded to integers.  Split Files is not supported.</p>

  <p>The procedure requires the installation of some items that are not
  provided in its installation.  See the section on installation later in this document
  for information on how to install these.
  </p>

<p><strong>VARIABLES</strong> specifies  the variables to be
  processed using the SPELLING, FREQUENCIES, and SEARCH subcommands.  If multiple tasks are specified
they are executed in the subcommand order listed above.</p>
   <p class="bullet">• Variable names must be legal as Python variables.  Statistics names are
   more general.  In particular, names for this procedure must not have periods in them, which
   Statistics allows.  Rename any such variables you want to use.</p>
   
<p><strong>OVERWRITE</strong> specifies whether output variables can overwrite existing variables.
If <strong>OVERWRITE=NO</strong> is specified and the
  output name is already in use, a numerical suffix is added to avoid overwriting.</P>
<P><strong>STEMMERLANG</strong> specifies the language to be used by the stemmer if doing stemming.
It should generally match the stopwords language, but coverage is uneven, so this may not always be possible.
PORTER is similar to the Porter English stemmer, but english is generally a better choice.  
Technical details about stemming can be found
<a href="https://snowballstem.org/algorithms/">here</a></p>
  
<h2>SPELLING</h2>  
<p><strong>DOSPELLING</strong> specifies whether spelling correction is done or not.
Corrected text is always in lower case except that the case of the first letter of a word is preserved
  if that letter was not changed in the correction.
  The spelling correction is not interactive and will sometimes guess wrong.
	It can also be very slow.</p>

<p><strong>EXCLUDENAMES</strong> specifies whether to correct people's names or not.  The procedure has
  over 7500 names built in.  They are mostly first names.</p>
  
<p><strong>EXTRADICT</strong> specifies an additional dictionary to use along with the built-in one.
 If the text includes a specialized vocabulary
   such as technical terms or abbreviations of organization names, the results will be better if a
   supplemental dictionary is included to prevent such words from being "corrected".  The dictionary file is
   just plain text with one entry per line.  Once loaded, that dictionary is included in subsequent
   spelling tasks in the session unless the dictionary language is changed. </p>
   <p>One source of a large collection of words is <br/>
<a href="https://github.com/dwyl/english-words/blob/master/words.zip">spelling dictionary</a>
<br/>
Extract the words.txt file from words.zip and specify it as an extra dictionary.
You can also get a list with just words with alpha characters there.
That location also contains words for some other languages.
</p>
  <p class="bullet">• The spelling correction is not interactive and will sometimes guess wrong.
	It can also be very slow.  The checker is not interactive and may well be wrong, 
	so experimentation may be necessary in determining whether to use it or not.  
	You can improve performance by creating a dataset with only the variables for 
	which you want to correct spelling and then merging the result back with the main dataset.</p>
 <p><strong>SUFFIX</strong> specifies the suffix to be used in forming output names.  The default is "cor".</p>
 
 <p><strong>LANGUAGE</strong> specifies which built-in spelling dictionary to use.</p>
 
<h2>FREQUENCIES</h2>
 <p><strong>DOFREQ</strong> specifies whether frequency tables are produced.  
 There are three tables per variable: word frequencies, bigram frequencies, and trigram frequencies listing
the most frequently occurring words up to the specified table limit size.</p>
<p><strong>STEM</strong> specifies whether to calculate the frequencies using the stemmed
values of the words or not.  Stemming means reducing words to their root form such as removing plurals.</p>
<p><strong>COUNT</strong> specifies the maximum number of items to display in the tables.  The default is 10.</p>
<h2>SENTIMENT</h2>
<p><strong>DOSENT</strong> specifies whether to do sentiment calculations or not.
This scores the degree of positive or negative
sentiment in the text.  For each case, it produces one to four score variables.  The possible measures are
negative, neutral, positive, and compound.  Compound combines the scores into an overall sentiment where
positive values indicate a positive sentiment and negative values the opposite.  Unrecognized words are considered neutral.</p>
<p>See<br/>
Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis
 of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.<br/>
for details on the VADER scores.</p>
<p><strong>TYPES</strong> specifies the types of scores to compute.</p>
<p><strong>SUFFIXES</strong> specifies the desired suffixes in the order of the types as listed above.
The defauls are neg, neu, pos, and comp.</p>

<h2>SEARCH</h2>
<p><strong>DOSEARCH</strong> specifies whether word searches are done or not.</p>
<p><strong>WORDS</strong> specifies the list of words or n-grams to search for.
To specify an n-gram, enter a hyphen between the words.  For example, good-time would be interpreted as a bigram.
Searches are not case sensitive.</p>
<p><strong>POSP</strong> specifies whether and how to include synonyms in the search.
Besides searching for exact words, you can include synonyms in the search.  If any synonym is found, it counts as a hit for the main word.  What synonyms are included is specified in the POSP string.  The choices are
<ul>
<li>x	do not search synonyms</li>
<li>n	noun</li>
<li>v	verb</li>
<li>a	adjective</li>
<li>r	adverb</li>
<li>y	any</li>
</ul>
For bigrams, specify two symbols and for trigrams specify three.  For example, xn would mean no synonyms for the first word in a bigram – just the word itself - followed by a noun synonym.  A part of speech code is required for every entry except that if none are specified, x is assumed, and if just one set is given, it is used for all terms.  As a shortcut, if the symbol string is short, it is padded with x'es.</p>
<p>For n-grams, each synonym for the first word is combined with each synonym for the second word and so on, so the possibilities can get quite large.  Consider using x for some words in an n-gram.</p>
<p>You can alternatively write the parts of speech as a parenthesized list following each word.  For example,<br/>
direction(n) different-direction(nv) social-aspects(a) he-is-young(xxy) ideas(n)<br/>
The dialog box always generates the first form, but writing syntax may be more convenient in the second.  You cannot mix the two: use POSP for everything or
put all the part-of-speech specifications in the parenthesized form.
<p>The term itself is always included in the synonym set, so an unknown word will have itself as a synonym.
</p>
<p><strong>LANG</strong> specifies the language for synonym searches.  The LANG parameter only affects the synonym search.  The following choices are available at this writing.  Additional languages
may become available in the future.  The language codes are ISO-639 standards.
The choices are<br/>
eng	english<br/>
arb	arabic<br/>
bul	bulgarian<br/>
cat	catalan<br/>
cmn	chinese (simplified)<br/>
dan	danish<br/>
ell	greek<br/>
eus	basque<br/>
fas	persian<br/>
fin	finnish<br/>
fra	french<br/>
glg	galacian<br/>
heb	hebrew<br/>
hrv	croation<br/>
ind	indonesian<br/>
ita	italian<br/>
jpn	japanese<br/>
nld	dutch<br/>
nno	norwegian<br/>
nob	norwegian (bokmal)<br/>
pol	polish<br/>
por	portuguese<br/>
slv	slovakian<br/>
spa	spanish<br/>
swe	swedish<br/>
tha	thai<br/>
</p>
 
<p><strong>DISPLAYSYN</strong>=YES to display the set of synonyms.  For example, for the trigram he-is-young with part of speech specified as xxn, the synonym set is</br>
<blockquote>(he, is, Whitney-Young), (he, is, Lester-Willis-Young), (he, is, Pres-Young), (he, is, Cy-Young), (he, is, Brigham-Young), (he, is, young), (he, is, Danton-True-Young), (he, is, new), (he, is, offspring), (he, is, Loretta-Young), (he, is, unseasoned), (he, is, youthful), (he, is, Whitney-Moore-Young-Jr.), (he, is, immature), (he, is, vernal), (he, is, Edward-Young), (he, is, youth), (he, is, untried), (he, is, Thomas-Young), (he, is, untested), (he, is, Young)</blockquote>
<p>Any of these items would be considered a hit.  Notice that besides several proper names, synonyms include young, youthful, immature, vernal, youth, untried, and untested following he-is.</p>
The term itself is always included in the synonym set, so an unknown word will have itself as a synonym.



<p><strong>MODE</strong> specifies whether the search is for all items listed or any of the items or a pattern.  The outcome
variable is 1 (true) if the search is successfull and 0 (false) otherwise except that if there is no text,
the value is system missing (numeric) or blank (string).  For PATTERN, the result is a sequence of 1 and 0 values with one value per search item.
A custom variable attribute named search is created that records the search criterion. <p>
<p><strong>SUFFIX</strong> specifies the suffix to be appended to the output variable name.  The default is
ser.</p>
<p><strong>STEM</strong> specifies whether to stem words in the variables before searching.  The search
item list is not stemmed.</p>

<h2>ENTITYSEARCH</h2>
<p><strong>ENTITYSEARCH</strong> looks for types of items such as persons without an explicit list of texts but using the grammar of the text (English only).  
Entities will not always be accurately detected due to the vagaries of speech and the vocabulary limitations.  Since the entity classification uses the grammar of the text, entity search seems not to work well with simple lists.  An entity may include other types of entities.  Filtering happens on the main item.</p>
<p><strong>ETYPE</strong> specifies the type of entity to search for.  The entity types are as follows.  Only one keyword can be given.  See the dialog box
help for examples of these types.
Additional entity types might be available.</p>
<ul>
<li>ALLTYPES -search for all entity types</li>
<li>ORG - ORGANIZATION</li>
<li>PER - PERSON</li>
<li>LOC - LOCATION</li>
<li>FAC - FACILITY</li>
<li>GPE - Geo-Political Entity</li>
</ul>
<p><strong>OUTSIZE</strong> specifies the width of the output variables in bytes.  The output includes the entity type and
each distinct entity for a case, separated by /.  Duplicate entities in a case are eliminated.</p>

<h2>LEXICON</h2>
<p><strong>DOLEXICON</strong> specifies whether or not to create a lexicon dataset from the sentiment definition.
The dataset contains the words and sentiment scores used in the scoring dictionary.  There are also booster words
such as very and somewhat that do not appear in the lexicon.</p>
<p><strong>DSNAME</strong> specifies the name for the dataset.</p>

<h2>WORDSCORES</h2>
<p><strong>DOSCORES</STRONG> specifies whether a sentiment scores files should be loaded.</p>
<p><strong>FILE</strong> specifies the name of the file to be loaded.  If you generate a lexicon file first,
you can see how the built-in words are scored as a guide to assigning scores to additional words.  You can
also change the scores for existing words this way.  The file should be encoded as utf-8.</p>

<h2>SPECIALTERMS</h2>
<p><strong>DOTERMS</STRONG> specifies whether the following keywords should be executed.</p>
<p><strong>NEGATIONFILE</strong> specifies a file containing a list of negation terms
to be added to the built-in terms.</p>
<p><strong>EMPHASISFILE</strong> specifies a file containing a list of emphasis terms
and scores to be added to the built-in terms.</p>
<p><strong>NEGATIONDSNAME</strong> specifies a new dataset to be created listing all the
negation terms.</p>
<p><strong>EMPHASISDSNAME</strong> specifies a new dataset to be created listing all the
emphasis terms and their scores.</p>
<p class="bullet">• If a file is loaded and the corresponding dataset is created, the
dataset will include the material from the file.</p>

<h2>STEMS</h2
<p><strong>DOSTEM</STRONG> specifies whether to produce variables containing the results of stemming
the variables.  Stemming often produces results that go further than
might be expected, so it can be useful to see how it works.  For example, "meetings" is stemmed to "meet", not "meeting".</p>

<p><strong>SUFFIX</STRONG> specifies the suffix to be used to construct the output variable names.</p>

<h1>Installation</h1>
<p>This procedure requires several additional items.
nltk files names.zip, stopwords.zip, wordnet.zip, and vader_lexicon.zip will
be installed over the Internet if they are not present.
However, the spell checking dictionary must be installed by the user.
Download the spelling dictionary from
<a href="https://github.com/dwyl/english-words/blob/master/words.zip">here</a><br>

 and extract the words.txt file from words.zip.  Specify that location when you run the procedure.
<p>If the SPSSINC TRANS extension command is not already installed, get it from the
Extensions > Extension Hub menu.</p>
<p>If the nltk toolkit is not found when the command is run, you will need to install it using
the STATS PACKAGE INSTALL extension command, which can also be obtained via Extensions > Extension Hub.</p>
<p>If you need to update the installed data packages - names, stopwords, wordnet, or vader_lexicon, 
open a syntax window in Statistics, and run this code.<br><code>
BEGIN PROGRAM PYTHON3.<br>
import nltk<br>
nltk.download()<br>
END PROGRAM.<br>
</code>
This will display a window with a table of items you can add to your installation.</p>


<h1>Acknowledgements</h1>
STATS TEXTANALYSIS relies on open source packages for linguistic analysis and spelling correction.
<ul>
<li>The NLTK project is led by Steven Bird and Liling Tan</li>
<li>Pyspellchecker Author: Tyler Barrus</li>
<li>Peter Norvig blog post on setting up a simple spell checking algorithm</li>
<li>P Lison and J Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles. 
In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)</li>
</ul>




<p>&copy; Copyright(C) Jon K. Peck, 2021</p>

</body>

</html>

